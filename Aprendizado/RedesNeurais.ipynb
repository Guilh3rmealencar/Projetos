{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RedesNeurais.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMhvFlUMRXvUSnUbhoPrRBJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"LFOf1CLXC1GG","executionInfo":{"status":"ok","timestamp":1642792746928,"user_tz":180,"elapsed":1149,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import plotly.express as px"]},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier"],"metadata":{"id":"Ma6fGeYpC82Z","executionInfo":{"status":"ok","timestamp":1642792746928,"user_tz":180,"elapsed":16,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pickle\n","with open('credit.pkl', 'rb') as f:  \n","  x_credit_treinamento, y_credit_treinamento, x_credit_teste, y_credit_teste = pickle.load(f)"],"metadata":{"id":"UOCcFRToC-3G","executionInfo":{"status":"ok","timestamp":1642792746929,"user_tz":180,"elapsed":16,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["x_credit_treinamento.shape, y_credit_treinamento.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjyNgQc5DQ0y","executionInfo":{"status":"ok","timestamp":1642792746929,"user_tz":180,"elapsed":16,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"7e84a435-f4ea-4ee8-e0c0-acea5766f4c3"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1500, 3), (1500,))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["x_credit_teste.shape, y_credit_teste.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zB5gHcTDTh6","executionInfo":{"status":"ok","timestamp":1642792746930,"user_tz":180,"elapsed":14,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"659bcb05-bc99-4415-8f4c-acd58892a270"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((500, 3), (500,))"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["(3 + 1) / 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFHZ42dTDTqo","executionInfo":{"status":"ok","timestamp":1642792746930,"user_tz":180,"elapsed":12,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"2a2ac61d-cbe2-4d14-e3a9-9052d0140423"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.0"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["rede_neural_credit = MLPClassifier(max_iter=1500, verbose=True, tol=0.0000100,\n","                                   solver = 'adam', activation = 'relu',\n","                                   hidden_layer_sizes = (20,20))\n","rede_neural_credit.fit(x_credit_treinamento, y_credit_treinamento)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2VdlQ-rRDY2x","executionInfo":{"status":"ok","timestamp":1642792752633,"user_tz":180,"elapsed":5712,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"1a293077-f6cd-4a5d-d1aa-e50f93bf9e31"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 1, loss = 0.52412085\n","Iteration 2, loss = 0.49564411\n","Iteration 3, loss = 0.46937502\n","Iteration 4, loss = 0.44487359\n","Iteration 5, loss = 0.42183010\n","Iteration 6, loss = 0.39955801\n","Iteration 7, loss = 0.37802524\n","Iteration 8, loss = 0.35592676\n","Iteration 9, loss = 0.33316094\n","Iteration 10, loss = 0.31093108\n","Iteration 11, loss = 0.28953207\n","Iteration 12, loss = 0.26905377\n","Iteration 13, loss = 0.25012757\n","Iteration 14, loss = 0.23180486\n","Iteration 15, loss = 0.21561929\n","Iteration 16, loss = 0.20054540\n","Iteration 17, loss = 0.18683999\n","Iteration 18, loss = 0.17432239\n","Iteration 19, loss = 0.16288467\n","Iteration 20, loss = 0.15223488\n","Iteration 21, loss = 0.14291464\n","Iteration 22, loss = 0.13440818\n","Iteration 23, loss = 0.12661726\n","Iteration 24, loss = 0.11986389\n","Iteration 25, loss = 0.11349568\n","Iteration 26, loss = 0.10792917\n","Iteration 27, loss = 0.10282264\n","Iteration 28, loss = 0.09844025\n","Iteration 29, loss = 0.09442515\n","Iteration 30, loss = 0.09071832\n","Iteration 31, loss = 0.08752025\n","Iteration 32, loss = 0.08444555\n","Iteration 33, loss = 0.08155484\n","Iteration 34, loss = 0.07903060\n","Iteration 35, loss = 0.07656101\n","Iteration 36, loss = 0.07441109\n","Iteration 37, loss = 0.07232730\n","Iteration 38, loss = 0.07038361\n","Iteration 39, loss = 0.06859850\n","Iteration 40, loss = 0.06704376\n","Iteration 41, loss = 0.06521534\n","Iteration 42, loss = 0.06374043\n","Iteration 43, loss = 0.06238917\n","Iteration 44, loss = 0.06104060\n","Iteration 45, loss = 0.05973453\n","Iteration 46, loss = 0.05858883\n","Iteration 47, loss = 0.05738387\n","Iteration 48, loss = 0.05617706\n","Iteration 49, loss = 0.05514372\n","Iteration 50, loss = 0.05411113\n","Iteration 51, loss = 0.05308226\n","Iteration 52, loss = 0.05221034\n","Iteration 53, loss = 0.05154864\n","Iteration 54, loss = 0.05020139\n","Iteration 55, loss = 0.04929253\n","Iteration 56, loss = 0.04864490\n","Iteration 57, loss = 0.04769094\n","Iteration 58, loss = 0.04704860\n","Iteration 59, loss = 0.04631456\n","Iteration 60, loss = 0.04539715\n","Iteration 61, loss = 0.04466489\n","Iteration 62, loss = 0.04397249\n","Iteration 63, loss = 0.04329149\n","Iteration 64, loss = 0.04282300\n","Iteration 65, loss = 0.04201738\n","Iteration 66, loss = 0.04136657\n","Iteration 67, loss = 0.04073271\n","Iteration 68, loss = 0.04006477\n","Iteration 69, loss = 0.03948506\n","Iteration 70, loss = 0.03887206\n","Iteration 71, loss = 0.03828175\n","Iteration 72, loss = 0.03775847\n","Iteration 73, loss = 0.03732277\n","Iteration 74, loss = 0.03674158\n","Iteration 75, loss = 0.03675279\n","Iteration 76, loss = 0.03585178\n","Iteration 77, loss = 0.03524363\n","Iteration 78, loss = 0.03489298\n","Iteration 79, loss = 0.03433986\n","Iteration 80, loss = 0.03378993\n","Iteration 81, loss = 0.03340143\n","Iteration 82, loss = 0.03295047\n","Iteration 83, loss = 0.03264708\n","Iteration 84, loss = 0.03215713\n","Iteration 85, loss = 0.03170780\n","Iteration 86, loss = 0.03132570\n","Iteration 87, loss = 0.03099659\n","Iteration 88, loss = 0.03052586\n","Iteration 89, loss = 0.03027009\n","Iteration 90, loss = 0.02990662\n","Iteration 91, loss = 0.02949947\n","Iteration 92, loss = 0.02919002\n","Iteration 93, loss = 0.02883925\n","Iteration 94, loss = 0.02846009\n","Iteration 95, loss = 0.02810312\n","Iteration 96, loss = 0.02777039\n","Iteration 97, loss = 0.02751583\n","Iteration 98, loss = 0.02721228\n","Iteration 99, loss = 0.02681875\n","Iteration 100, loss = 0.02661726\n","Iteration 101, loss = 0.02641417\n","Iteration 102, loss = 0.02600978\n","Iteration 103, loss = 0.02566846\n","Iteration 104, loss = 0.02538385\n","Iteration 105, loss = 0.02515562\n","Iteration 106, loss = 0.02491665\n","Iteration 107, loss = 0.02457893\n","Iteration 108, loss = 0.02427932\n","Iteration 109, loss = 0.02402492\n","Iteration 110, loss = 0.02387499\n","Iteration 111, loss = 0.02384199\n","Iteration 112, loss = 0.02340346\n","Iteration 113, loss = 0.02299870\n","Iteration 114, loss = 0.02277939\n","Iteration 115, loss = 0.02249603\n","Iteration 116, loss = 0.02242633\n","Iteration 117, loss = 0.02209748\n","Iteration 118, loss = 0.02189751\n","Iteration 119, loss = 0.02170922\n","Iteration 120, loss = 0.02138815\n","Iteration 121, loss = 0.02113287\n","Iteration 122, loss = 0.02099384\n","Iteration 123, loss = 0.02083874\n","Iteration 124, loss = 0.02058302\n","Iteration 125, loss = 0.02035434\n","Iteration 126, loss = 0.02014819\n","Iteration 127, loss = 0.01998636\n","Iteration 128, loss = 0.01985200\n","Iteration 129, loss = 0.01961038\n","Iteration 130, loss = 0.01933066\n","Iteration 131, loss = 0.01923173\n","Iteration 132, loss = 0.01910673\n","Iteration 133, loss = 0.01885736\n","Iteration 134, loss = 0.01869228\n","Iteration 135, loss = 0.01849988\n","Iteration 136, loss = 0.01838855\n","Iteration 137, loss = 0.01830593\n","Iteration 138, loss = 0.01807864\n","Iteration 139, loss = 0.01816893\n","Iteration 140, loss = 0.01768773\n","Iteration 141, loss = 0.01774069\n","Iteration 142, loss = 0.01750365\n","Iteration 143, loss = 0.01742236\n","Iteration 144, loss = 0.01716543\n","Iteration 145, loss = 0.01704189\n","Iteration 146, loss = 0.01692831\n","Iteration 147, loss = 0.01692665\n","Iteration 148, loss = 0.01678962\n","Iteration 149, loss = 0.01654069\n","Iteration 150, loss = 0.01638816\n","Iteration 151, loss = 0.01633539\n","Iteration 152, loss = 0.01611112\n","Iteration 153, loss = 0.01600180\n","Iteration 154, loss = 0.01596798\n","Iteration 155, loss = 0.01575386\n","Iteration 156, loss = 0.01558196\n","Iteration 157, loss = 0.01544308\n","Iteration 158, loss = 0.01536008\n","Iteration 159, loss = 0.01516535\n","Iteration 160, loss = 0.01514549\n","Iteration 161, loss = 0.01495131\n","Iteration 162, loss = 0.01495842\n","Iteration 163, loss = 0.01477192\n","Iteration 164, loss = 0.01482629\n","Iteration 165, loss = 0.01463101\n","Iteration 166, loss = 0.01445153\n","Iteration 167, loss = 0.01441284\n","Iteration 168, loss = 0.01427842\n","Iteration 169, loss = 0.01421806\n","Iteration 170, loss = 0.01401864\n","Iteration 171, loss = 0.01397917\n","Iteration 172, loss = 0.01390664\n","Iteration 173, loss = 0.01374502\n","Iteration 174, loss = 0.01370977\n","Iteration 175, loss = 0.01353061\n","Iteration 176, loss = 0.01361129\n","Iteration 177, loss = 0.01376500\n","Iteration 178, loss = 0.01342247\n","Iteration 179, loss = 0.01344453\n","Iteration 180, loss = 0.01296755\n","Iteration 181, loss = 0.01303559\n","Iteration 182, loss = 0.01309997\n","Iteration 183, loss = 0.01291733\n","Iteration 184, loss = 0.01274640\n","Iteration 185, loss = 0.01262138\n","Iteration 186, loss = 0.01254682\n","Iteration 187, loss = 0.01255822\n","Iteration 188, loss = 0.01263869\n","Iteration 189, loss = 0.01238549\n","Iteration 190, loss = 0.01222386\n","Iteration 191, loss = 0.01230589\n","Iteration 192, loss = 0.01207422\n","Iteration 193, loss = 0.01204961\n","Iteration 194, loss = 0.01194554\n","Iteration 195, loss = 0.01189551\n","Iteration 196, loss = 0.01184498\n","Iteration 197, loss = 0.01175749\n","Iteration 198, loss = 0.01172756\n","Iteration 199, loss = 0.01159236\n","Iteration 200, loss = 0.01169880\n","Iteration 201, loss = 0.01143669\n","Iteration 202, loss = 0.01137367\n","Iteration 203, loss = 0.01130409\n","Iteration 204, loss = 0.01126460\n","Iteration 205, loss = 0.01128237\n","Iteration 206, loss = 0.01112107\n","Iteration 207, loss = 0.01114413\n","Iteration 208, loss = 0.01120093\n","Iteration 209, loss = 0.01100132\n","Iteration 210, loss = 0.01078368\n","Iteration 211, loss = 0.01089415\n","Iteration 212, loss = 0.01079542\n","Iteration 213, loss = 0.01070020\n","Iteration 214, loss = 0.01068172\n","Iteration 215, loss = 0.01065817\n","Iteration 216, loss = 0.01052288\n","Iteration 217, loss = 0.01052197\n","Iteration 218, loss = 0.01033555\n","Iteration 219, loss = 0.01033787\n","Iteration 220, loss = 0.01020611\n","Iteration 221, loss = 0.01014330\n","Iteration 222, loss = 0.01005483\n","Iteration 223, loss = 0.01008022\n","Iteration 224, loss = 0.01015028\n","Iteration 225, loss = 0.00990628\n","Iteration 226, loss = 0.00983817\n","Iteration 227, loss = 0.00985654\n","Iteration 228, loss = 0.00980310\n","Iteration 229, loss = 0.00969090\n","Iteration 230, loss = 0.00962805\n","Iteration 231, loss = 0.00956022\n","Iteration 232, loss = 0.00955712\n","Iteration 233, loss = 0.00956780\n","Iteration 234, loss = 0.00949455\n","Iteration 235, loss = 0.00949275\n","Iteration 236, loss = 0.00941129\n","Iteration 237, loss = 0.00926773\n","Iteration 238, loss = 0.00919665\n","Iteration 239, loss = 0.00929011\n","Iteration 240, loss = 0.00919056\n","Iteration 241, loss = 0.00912222\n","Iteration 242, loss = 0.00909609\n","Iteration 243, loss = 0.00887874\n","Iteration 244, loss = 0.00900769\n","Iteration 245, loss = 0.00905773\n","Iteration 246, loss = 0.00881911\n","Iteration 247, loss = 0.00878868\n","Iteration 248, loss = 0.00875655\n","Iteration 249, loss = 0.00922142\n","Iteration 250, loss = 0.00882960\n","Iteration 251, loss = 0.00893123\n","Iteration 252, loss = 0.00853930\n","Iteration 253, loss = 0.00857214\n","Iteration 254, loss = 0.00850867\n","Iteration 255, loss = 0.00859386\n","Iteration 256, loss = 0.00839454\n","Iteration 257, loss = 0.00852276\n","Iteration 258, loss = 0.00833862\n","Iteration 259, loss = 0.00843467\n","Iteration 260, loss = 0.00820969\n","Iteration 261, loss = 0.00817742\n","Iteration 262, loss = 0.00810855\n","Iteration 263, loss = 0.00809500\n","Iteration 264, loss = 0.00807483\n","Iteration 265, loss = 0.00795558\n","Iteration 266, loss = 0.00805938\n","Iteration 267, loss = 0.00792996\n","Iteration 268, loss = 0.00788590\n","Iteration 269, loss = 0.00787680\n","Iteration 270, loss = 0.00781957\n","Iteration 271, loss = 0.00779579\n","Iteration 272, loss = 0.00770413\n","Iteration 273, loss = 0.00780191\n","Iteration 274, loss = 0.00771099\n","Iteration 275, loss = 0.00777795\n","Iteration 276, loss = 0.00764431\n","Iteration 277, loss = 0.00752676\n","Iteration 278, loss = 0.00759321\n","Iteration 279, loss = 0.00742500\n","Iteration 280, loss = 0.00749900\n","Iteration 281, loss = 0.00740471\n","Iteration 282, loss = 0.00733959\n","Iteration 283, loss = 0.00736201\n","Iteration 284, loss = 0.00735087\n","Iteration 285, loss = 0.00726561\n","Iteration 286, loss = 0.00716479\n","Iteration 287, loss = 0.00732963\n","Iteration 288, loss = 0.00718807\n","Iteration 289, loss = 0.00727653\n","Iteration 290, loss = 0.00710319\n","Iteration 291, loss = 0.00716982\n","Iteration 292, loss = 0.00724376\n","Iteration 293, loss = 0.00715018\n","Iteration 294, loss = 0.00697730\n","Iteration 295, loss = 0.00708019\n","Iteration 296, loss = 0.00700408\n","Iteration 297, loss = 0.00687709\n","Iteration 298, loss = 0.00686164\n","Iteration 299, loss = 0.00680544\n","Iteration 300, loss = 0.00670206\n","Iteration 301, loss = 0.00672800\n","Iteration 302, loss = 0.00667434\n","Iteration 303, loss = 0.00667670\n","Iteration 304, loss = 0.00677253\n","Iteration 305, loss = 0.00669289\n","Iteration 306, loss = 0.00667156\n","Iteration 307, loss = 0.00642723\n","Iteration 308, loss = 0.00648387\n","Iteration 309, loss = 0.00644667\n","Iteration 310, loss = 0.00650863\n","Iteration 311, loss = 0.00638322\n","Iteration 312, loss = 0.00651546\n","Iteration 313, loss = 0.00653217\n","Iteration 314, loss = 0.00656893\n","Iteration 315, loss = 0.00639249\n","Iteration 316, loss = 0.00629896\n","Iteration 317, loss = 0.00624817\n","Iteration 318, loss = 0.00631157\n","Iteration 319, loss = 0.00632895\n","Iteration 320, loss = 0.00612732\n","Iteration 321, loss = 0.00621597\n","Iteration 322, loss = 0.00612738\n","Iteration 323, loss = 0.00615955\n","Iteration 324, loss = 0.00605729\n","Iteration 325, loss = 0.00593781\n","Iteration 326, loss = 0.00615400\n","Iteration 327, loss = 0.00612324\n","Iteration 328, loss = 0.00597062\n","Iteration 329, loss = 0.00595945\n","Iteration 330, loss = 0.00608429\n","Iteration 331, loss = 0.00591844\n","Iteration 332, loss = 0.00603884\n","Iteration 333, loss = 0.00578991\n","Iteration 334, loss = 0.00586952\n","Iteration 335, loss = 0.00574218\n","Iteration 336, loss = 0.00570125\n","Iteration 337, loss = 0.00589534\n","Iteration 338, loss = 0.00567044\n","Iteration 339, loss = 0.00563638\n","Iteration 340, loss = 0.00581427\n","Iteration 341, loss = 0.00559271\n","Iteration 342, loss = 0.00558173\n","Iteration 343, loss = 0.00558515\n","Iteration 344, loss = 0.00563386\n","Iteration 345, loss = 0.00546571\n","Iteration 346, loss = 0.00545925\n","Iteration 347, loss = 0.00551879\n","Iteration 348, loss = 0.00563491\n","Iteration 349, loss = 0.00555063\n","Iteration 350, loss = 0.00560056\n","Iteration 351, loss = 0.00537445\n","Iteration 352, loss = 0.00541271\n","Iteration 353, loss = 0.00530271\n","Iteration 354, loss = 0.00529485\n","Iteration 355, loss = 0.00536835\n","Iteration 356, loss = 0.00525174\n","Iteration 357, loss = 0.00537337\n","Iteration 358, loss = 0.00517287\n","Iteration 359, loss = 0.00541805\n","Iteration 360, loss = 0.00516324\n","Iteration 361, loss = 0.00512860\n","Iteration 362, loss = 0.00524138\n","Iteration 363, loss = 0.00510168\n","Iteration 364, loss = 0.00523561\n","Iteration 365, loss = 0.00510671\n","Iteration 366, loss = 0.00517417\n","Iteration 367, loss = 0.00504972\n","Iteration 368, loss = 0.00501561\n","Iteration 369, loss = 0.00495096\n","Iteration 370, loss = 0.00506456\n","Iteration 371, loss = 0.00496204\n","Iteration 372, loss = 0.00499900\n","Iteration 373, loss = 0.00505129\n","Iteration 374, loss = 0.00497098\n","Iteration 375, loss = 0.00484837\n","Iteration 376, loss = 0.00492533\n","Iteration 377, loss = 0.00479901\n","Iteration 378, loss = 0.00475218\n","Iteration 379, loss = 0.00487151\n","Iteration 380, loss = 0.00474357\n","Iteration 381, loss = 0.00473449\n","Iteration 382, loss = 0.00476919\n","Iteration 383, loss = 0.00469142\n","Iteration 384, loss = 0.00467719\n","Iteration 385, loss = 0.00463742\n","Iteration 386, loss = 0.00472907\n","Iteration 387, loss = 0.00464067\n","Iteration 388, loss = 0.00488318\n","Iteration 389, loss = 0.00469513\n","Iteration 390, loss = 0.00455935\n","Iteration 391, loss = 0.00457073\n","Iteration 392, loss = 0.00454126\n","Iteration 393, loss = 0.00450773\n","Iteration 394, loss = 0.00465998\n","Iteration 395, loss = 0.00456495\n","Iteration 396, loss = 0.00457120\n","Iteration 397, loss = 0.00458851\n","Iteration 398, loss = 0.00434718\n","Iteration 399, loss = 0.00451528\n","Iteration 400, loss = 0.00448268\n","Iteration 401, loss = 0.00441317\n","Iteration 402, loss = 0.00440548\n","Iteration 403, loss = 0.00439901\n","Iteration 404, loss = 0.00425224\n","Iteration 405, loss = 0.00426180\n","Iteration 406, loss = 0.00433893\n","Iteration 407, loss = 0.00432393\n","Iteration 408, loss = 0.00424754\n","Iteration 409, loss = 0.00422679\n","Iteration 410, loss = 0.00442984\n","Iteration 411, loss = 0.00413670\n","Iteration 412, loss = 0.00424343\n","Iteration 413, loss = 0.00415200\n","Iteration 414, loss = 0.00412104\n","Iteration 415, loss = 0.00424652\n","Iteration 416, loss = 0.00406647\n","Iteration 417, loss = 0.00416069\n","Iteration 418, loss = 0.00408108\n","Iteration 419, loss = 0.00404832\n","Iteration 420, loss = 0.00417074\n","Iteration 421, loss = 0.00411851\n","Iteration 422, loss = 0.00400715\n","Iteration 423, loss = 0.00402421\n","Iteration 424, loss = 0.00397614\n","Iteration 425, loss = 0.00397033\n","Iteration 426, loss = 0.00399216\n","Iteration 427, loss = 0.00396558\n","Iteration 428, loss = 0.00389976\n","Iteration 429, loss = 0.00395734\n","Iteration 430, loss = 0.00388699\n","Iteration 431, loss = 0.00394781\n","Iteration 432, loss = 0.00386663\n","Iteration 433, loss = 0.00381068\n","Iteration 434, loss = 0.00385539\n","Iteration 435, loss = 0.00383254\n","Iteration 436, loss = 0.00388021\n","Iteration 437, loss = 0.00379993\n","Iteration 438, loss = 0.00384456\n","Iteration 439, loss = 0.00371257\n","Iteration 440, loss = 0.00375117\n","Iteration 441, loss = 0.00377648\n","Iteration 442, loss = 0.00359034\n","Iteration 443, loss = 0.00368929\n","Iteration 444, loss = 0.00366060\n","Iteration 445, loss = 0.00370364\n","Iteration 446, loss = 0.00379210\n","Iteration 447, loss = 0.00378851\n","Iteration 448, loss = 0.00366375\n","Iteration 449, loss = 0.00358421\n","Iteration 450, loss = 0.00363097\n","Iteration 451, loss = 0.00353943\n","Iteration 452, loss = 0.00363901\n","Iteration 453, loss = 0.00351302\n","Iteration 454, loss = 0.00353148\n","Iteration 455, loss = 0.00351512\n","Iteration 456, loss = 0.00348323\n","Iteration 457, loss = 0.00355490\n","Iteration 458, loss = 0.00356152\n","Iteration 459, loss = 0.00346471\n","Iteration 460, loss = 0.00342020\n","Iteration 461, loss = 0.00342821\n","Iteration 462, loss = 0.00348084\n","Iteration 463, loss = 0.00354929\n","Iteration 464, loss = 0.00340333\n","Iteration 465, loss = 0.00342402\n","Iteration 466, loss = 0.00344257\n","Iteration 467, loss = 0.00335024\n","Iteration 468, loss = 0.00334706\n","Iteration 469, loss = 0.00329158\n","Iteration 470, loss = 0.00346398\n","Iteration 471, loss = 0.00330044\n","Iteration 472, loss = 0.00344816\n","Iteration 473, loss = 0.00325520\n","Iteration 474, loss = 0.00340387\n","Iteration 475, loss = 0.00344257\n","Iteration 476, loss = 0.00325880\n","Iteration 477, loss = 0.00327368\n","Iteration 478, loss = 0.00331730\n","Iteration 479, loss = 0.00332837\n","Iteration 480, loss = 0.00318572\n","Iteration 481, loss = 0.00320848\n","Iteration 482, loss = 0.00324128\n","Iteration 483, loss = 0.00319932\n","Iteration 484, loss = 0.00318152\n","Iteration 485, loss = 0.00316813\n","Iteration 486, loss = 0.00307349\n","Iteration 487, loss = 0.00312785\n","Iteration 488, loss = 0.00336728\n","Iteration 489, loss = 0.00330607\n","Iteration 490, loss = 0.00308595\n","Iteration 491, loss = 0.00312670\n","Iteration 492, loss = 0.00312948\n","Iteration 493, loss = 0.00301919\n","Iteration 494, loss = 0.00328038\n","Iteration 495, loss = 0.00304466\n","Iteration 496, loss = 0.00317047\n","Iteration 497, loss = 0.00293508\n","Iteration 498, loss = 0.00300768\n","Iteration 499, loss = 0.00295147\n","Iteration 500, loss = 0.00316337\n","Iteration 501, loss = 0.00315976\n","Iteration 502, loss = 0.00309360\n","Iteration 503, loss = 0.00290205\n","Iteration 504, loss = 0.00294138\n","Iteration 505, loss = 0.00293719\n","Iteration 506, loss = 0.00291263\n","Iteration 507, loss = 0.00285710\n","Iteration 508, loss = 0.00287910\n","Iteration 509, loss = 0.00287927\n","Iteration 510, loss = 0.00286950\n","Iteration 511, loss = 0.00285658\n","Iteration 512, loss = 0.00276535\n","Iteration 513, loss = 0.00282126\n","Iteration 514, loss = 0.00285367\n","Iteration 515, loss = 0.00277220\n","Iteration 516, loss = 0.00277432\n","Iteration 517, loss = 0.00278070\n","Iteration 518, loss = 0.00278350\n","Iteration 519, loss = 0.00274932\n","Iteration 520, loss = 0.00277005\n","Iteration 521, loss = 0.00273286\n","Iteration 522, loss = 0.00273146\n","Iteration 523, loss = 0.00267785\n","Iteration 524, loss = 0.00274788\n","Iteration 525, loss = 0.00266466\n","Iteration 526, loss = 0.00272409\n","Iteration 527, loss = 0.00279768\n","Iteration 528, loss = 0.00269060\n","Iteration 529, loss = 0.00270729\n","Iteration 530, loss = 0.00280263\n","Iteration 531, loss = 0.00259413\n","Iteration 532, loss = 0.00263239\n","Iteration 533, loss = 0.00268989\n","Iteration 534, loss = 0.00263978\n","Iteration 535, loss = 0.00270679\n","Iteration 536, loss = 0.00260732\n","Iteration 537, loss = 0.00259415\n","Iteration 538, loss = 0.00253316\n","Iteration 539, loss = 0.00252508\n","Iteration 540, loss = 0.00255250\n","Iteration 541, loss = 0.00250849\n","Iteration 542, loss = 0.00250966\n","Iteration 543, loss = 0.00252855\n","Iteration 544, loss = 0.00252735\n","Iteration 545, loss = 0.00252769\n","Iteration 546, loss = 0.00245763\n","Iteration 547, loss = 0.00249448\n","Iteration 548, loss = 0.00252778\n","Iteration 549, loss = 0.00256554\n","Iteration 550, loss = 0.00242725\n","Iteration 551, loss = 0.00250600\n","Iteration 552, loss = 0.00256864\n","Iteration 553, loss = 0.00244182\n","Iteration 554, loss = 0.00241847\n","Iteration 555, loss = 0.00238038\n","Iteration 556, loss = 0.00240970\n","Iteration 557, loss = 0.00241213\n","Iteration 558, loss = 0.00236476\n","Iteration 559, loss = 0.00234171\n","Iteration 560, loss = 0.00246282\n","Iteration 561, loss = 0.00235238\n","Iteration 562, loss = 0.00239014\n","Iteration 563, loss = 0.00230164\n","Iteration 564, loss = 0.00231278\n","Iteration 565, loss = 0.00230114\n","Iteration 566, loss = 0.00232673\n","Iteration 567, loss = 0.00232645\n","Iteration 568, loss = 0.00226801\n","Iteration 569, loss = 0.00228740\n","Iteration 570, loss = 0.00239504\n","Iteration 571, loss = 0.00225278\n","Iteration 572, loss = 0.00240233\n","Iteration 573, loss = 0.00224189\n","Iteration 574, loss = 0.00228108\n","Iteration 575, loss = 0.00222657\n","Iteration 576, loss = 0.00222005\n","Iteration 577, loss = 0.00234786\n","Iteration 578, loss = 0.00228673\n","Iteration 579, loss = 0.00215755\n","Iteration 580, loss = 0.00217865\n","Iteration 581, loss = 0.00222789\n","Iteration 582, loss = 0.00221369\n","Iteration 583, loss = 0.00218517\n","Iteration 584, loss = 0.00219101\n","Iteration 585, loss = 0.00218707\n","Iteration 586, loss = 0.00219261\n","Iteration 587, loss = 0.00213222\n","Iteration 588, loss = 0.00239812\n","Iteration 589, loss = 0.00214521\n","Iteration 590, loss = 0.00215000\n","Iteration 591, loss = 0.00209007\n","Iteration 592, loss = 0.00210880\n","Iteration 593, loss = 0.00205204\n","Iteration 594, loss = 0.00220247\n","Iteration 595, loss = 0.00219472\n","Iteration 596, loss = 0.00205580\n","Iteration 597, loss = 0.00213102\n","Iteration 598, loss = 0.00207887\n","Iteration 599, loss = 0.00205607\n","Iteration 600, loss = 0.00203755\n","Iteration 601, loss = 0.00199682\n","Iteration 602, loss = 0.00205583\n","Iteration 603, loss = 0.00199306\n","Iteration 604, loss = 0.00203198\n","Iteration 605, loss = 0.00220301\n","Iteration 606, loss = 0.00202696\n","Iteration 607, loss = 0.00195956\n","Iteration 608, loss = 0.00198762\n","Iteration 609, loss = 0.00198778\n","Iteration 610, loss = 0.00198593\n","Iteration 611, loss = 0.00210518\n","Iteration 612, loss = 0.00192714\n","Iteration 613, loss = 0.00197441\n","Iteration 614, loss = 0.00194213\n","Iteration 615, loss = 0.00196751\n","Iteration 616, loss = 0.00195776\n","Iteration 617, loss = 0.00190901\n","Iteration 618, loss = 0.00191006\n","Iteration 619, loss = 0.00195792\n","Iteration 620, loss = 0.00213119\n","Iteration 621, loss = 0.00189660\n","Iteration 622, loss = 0.00191180\n","Iteration 623, loss = 0.00183763\n","Iteration 624, loss = 0.00192845\n","Iteration 625, loss = 0.00182852\n","Iteration 626, loss = 0.00192773\n","Iteration 627, loss = 0.00182463\n","Iteration 628, loss = 0.00188545\n","Iteration 629, loss = 0.00188083\n","Iteration 630, loss = 0.00185750\n","Iteration 631, loss = 0.00181931\n","Iteration 632, loss = 0.00179557\n","Iteration 633, loss = 0.00185093\n","Iteration 634, loss = 0.00187105\n","Iteration 635, loss = 0.00179576\n","Iteration 636, loss = 0.00177468\n","Iteration 637, loss = 0.00181345\n","Iteration 638, loss = 0.00175146\n","Iteration 639, loss = 0.00177237\n","Iteration 640, loss = 0.00185709\n","Iteration 641, loss = 0.00180273\n","Iteration 642, loss = 0.00177940\n","Iteration 643, loss = 0.00175359\n","Iteration 644, loss = 0.00172284\n","Iteration 645, loss = 0.00170664\n","Iteration 646, loss = 0.00171540\n","Iteration 647, loss = 0.00173195\n","Iteration 648, loss = 0.00170399\n","Iteration 649, loss = 0.00169573\n","Iteration 650, loss = 0.00169334\n","Iteration 651, loss = 0.00171461\n","Iteration 652, loss = 0.00168981\n","Iteration 653, loss = 0.00167062\n","Iteration 654, loss = 0.00165529\n","Iteration 655, loss = 0.00173582\n","Iteration 656, loss = 0.00163961\n","Iteration 657, loss = 0.00172025\n","Iteration 658, loss = 0.00164084\n","Iteration 659, loss = 0.00164318\n","Iteration 660, loss = 0.00169234\n","Iteration 661, loss = 0.00161611\n","Iteration 662, loss = 0.00162544\n","Iteration 663, loss = 0.00163343\n","Iteration 664, loss = 0.00160736\n","Iteration 665, loss = 0.00163565\n","Iteration 666, loss = 0.00157396\n","Iteration 667, loss = 0.00171059\n","Iteration 668, loss = 0.00174263\n","Iteration 669, loss = 0.00160722\n","Iteration 670, loss = 0.00161771\n","Iteration 671, loss = 0.00162125\n","Iteration 672, loss = 0.00159215\n","Iteration 673, loss = 0.00156720\n","Iteration 674, loss = 0.00157164\n","Iteration 675, loss = 0.00154467\n","Iteration 676, loss = 0.00153149\n","Iteration 677, loss = 0.00157910\n","Iteration 678, loss = 0.00155542\n","Iteration 679, loss = 0.00155979\n","Iteration 680, loss = 0.00155412\n","Iteration 681, loss = 0.00153663\n","Iteration 682, loss = 0.00156960\n","Iteration 683, loss = 0.00155266\n","Iteration 684, loss = 0.00151144\n","Iteration 685, loss = 0.00151459\n","Iteration 686, loss = 0.00146865\n","Iteration 687, loss = 0.00158178\n","Iteration 688, loss = 0.00156828\n","Iteration 689, loss = 0.00148416\n","Iteration 690, loss = 0.00152848\n","Iteration 691, loss = 0.00152272\n","Iteration 692, loss = 0.00149551\n","Iteration 693, loss = 0.00145569\n","Iteration 694, loss = 0.00144934\n","Iteration 695, loss = 0.00150788\n","Iteration 696, loss = 0.00143984\n","Iteration 697, loss = 0.00143978\n","Iteration 698, loss = 0.00163783\n","Iteration 699, loss = 0.00145202\n","Iteration 700, loss = 0.00150685\n","Iteration 701, loss = 0.00152053\n","Iteration 702, loss = 0.00143280\n","Iteration 703, loss = 0.00142127\n","Iteration 704, loss = 0.00139412\n","Iteration 705, loss = 0.00139683\n","Iteration 706, loss = 0.00142534\n","Iteration 707, loss = 0.00146408\n","Iteration 708, loss = 0.00139981\n","Iteration 709, loss = 0.00148017\n","Iteration 710, loss = 0.00137204\n","Iteration 711, loss = 0.00138711\n","Iteration 712, loss = 0.00142408\n","Iteration 713, loss = 0.00130614\n","Iteration 714, loss = 0.00145618\n","Iteration 715, loss = 0.00138817\n","Iteration 716, loss = 0.00137229\n","Iteration 717, loss = 0.00136650\n","Iteration 718, loss = 0.00136653\n","Iteration 719, loss = 0.00148059\n","Iteration 720, loss = 0.00132556\n","Iteration 721, loss = 0.00139959\n","Iteration 722, loss = 0.00137567\n","Iteration 723, loss = 0.00132102\n","Iteration 724, loss = 0.00129948\n","Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"]},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=1500, tol=1e-05,\n","              verbose=True)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["previsoes = rede_neural_credit.predict(x_credit_teste)\n","previsoes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yT__0eeMDgA8","executionInfo":{"status":"ok","timestamp":1642792752634,"user_tz":180,"elapsed":24,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"42602f56-be74-46f6-f999-1939782c273a"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n","       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n","       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["y_credit_teste"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Y23QyXvDiTQ","executionInfo":{"status":"ok","timestamp":1642792752634,"user_tz":180,"elapsed":14,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"314b2cf3-b28f-4457-f986-3b63cd0e4751"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n","       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n","       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report\n","accuracy_score(y_credit_teste, previsoes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XtC-mUJnDiV8","executionInfo":{"status":"ok","timestamp":1642792752634,"user_tz":180,"elapsed":12,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"2420bc9a-35bf-49a5-ba0b-62d69868e513"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.992"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from yellowbrick.classifier import ConfusionMatrix\n","cm = ConfusionMatrix(rede_neural_credit)\n","cm.fit(x_credit_treinamento, y_credit_treinamento)\n","cm.score(x_credit_teste, y_credit_teste)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"vEf9rcwtDiYc","executionInfo":{"status":"ok","timestamp":1642792753224,"user_tz":180,"elapsed":600,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"96d57540-7c43-46cf-88d5-1fce68030829"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.992"]},"metadata":{},"execution_count":11},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["print(classification_report(y_credit_teste, previsoes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFpPtvjoDiax","executionInfo":{"status":"ok","timestamp":1642792753225,"user_tz":180,"elapsed":13,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"d397bbe3-6516-4b09-dcb4-a6cf9cca5f31"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00       436\n","           1       0.98      0.95      0.97        64\n","\n","    accuracy                           0.99       500\n","   macro avg       0.99      0.98      0.98       500\n","weighted avg       0.99      0.99      0.99       500\n","\n"]}]},{"cell_type":"code","source":["with open('census.pkl', 'rb') as f:  \n","  x_census_treinamento, y_census_treinamento, x_census_teste, y_census_teste = pickle.load(f)"],"metadata":{"id":"UN59TPyIDic4","executionInfo":{"status":"ok","timestamp":1642792753225,"user_tz":180,"elapsed":10,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["x_census_treinamento.shape, y_census_treinamento.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1o9Tpgl3DifF","executionInfo":{"status":"ok","timestamp":1642792753226,"user_tz":180,"elapsed":11,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"36265999-dcea-4782-c4ba-8ab524a9e717"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((27676, 108), (27676,))"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["x_census_teste.shape, y_census_teste.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esuxHKPhD2q4","executionInfo":{"status":"ok","timestamp":1642792753226,"user_tz":180,"elapsed":9,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"c003e82d-9344-4c18-f33d-7aecc1e1988a"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4885, 108), (4885,))"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["(108 + 1) / 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r5JJtyPjD2wE","executionInfo":{"status":"ok","timestamp":1642792753227,"user_tz":180,"elapsed":8,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"b386453a-b8c7-41cd-a351-c4f840602e1c"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["54.5"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["rede_neural_census = MLPClassifier(verbose=True, max_iter = 1000, tol=0.000010,\n","                                  hidden_layer_sizes = (55,55))\n","rede_neural_census.fit(x_census_treinamento, y_census_treinamento)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6yIhHseAD2yX","executionInfo":{"status":"ok","timestamp":1642792866632,"user_tz":180,"elapsed":113412,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"d54cc1a9-15fc-4adf-ab36-58a6545d7c6b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 1, loss = 0.38369964\n","Iteration 2, loss = 0.32759425\n","Iteration 3, loss = 0.31637685\n","Iteration 4, loss = 0.30910749\n","Iteration 5, loss = 0.30451922\n","Iteration 6, loss = 0.30116268\n","Iteration 7, loss = 0.29768164\n","Iteration 8, loss = 0.29442359\n","Iteration 9, loss = 0.29189856\n","Iteration 10, loss = 0.28909550\n","Iteration 11, loss = 0.28747003\n","Iteration 12, loss = 0.28548184\n","Iteration 13, loss = 0.28305781\n","Iteration 14, loss = 0.28179493\n","Iteration 15, loss = 0.27957613\n","Iteration 16, loss = 0.27838766\n","Iteration 17, loss = 0.27752325\n","Iteration 18, loss = 0.27511767\n","Iteration 19, loss = 0.27330270\n","Iteration 20, loss = 0.27142179\n","Iteration 21, loss = 0.26967809\n","Iteration 22, loss = 0.26885881\n","Iteration 23, loss = 0.26724214\n","Iteration 24, loss = 0.26526807\n","Iteration 25, loss = 0.26444452\n","Iteration 26, loss = 0.26283245\n","Iteration 27, loss = 0.26131213\n","Iteration 28, loss = 0.25994268\n","Iteration 29, loss = 0.25867368\n","Iteration 30, loss = 0.25674342\n","Iteration 31, loss = 0.25600554\n","Iteration 32, loss = 0.25412238\n","Iteration 33, loss = 0.25265871\n","Iteration 34, loss = 0.25245105\n","Iteration 35, loss = 0.25018978\n","Iteration 36, loss = 0.24925130\n","Iteration 37, loss = 0.24805232\n","Iteration 38, loss = 0.24654806\n","Iteration 39, loss = 0.24529895\n","Iteration 40, loss = 0.24379440\n","Iteration 41, loss = 0.24193776\n","Iteration 42, loss = 0.24239486\n","Iteration 43, loss = 0.24148257\n","Iteration 44, loss = 0.23899099\n","Iteration 45, loss = 0.23830801\n","Iteration 46, loss = 0.23796503\n","Iteration 47, loss = 0.23656328\n","Iteration 48, loss = 0.23624335\n","Iteration 49, loss = 0.23451986\n","Iteration 50, loss = 0.23356181\n","Iteration 51, loss = 0.23232796\n","Iteration 52, loss = 0.23200912\n","Iteration 53, loss = 0.23134543\n","Iteration 54, loss = 0.23067991\n","Iteration 55, loss = 0.22998698\n","Iteration 56, loss = 0.22864578\n","Iteration 57, loss = 0.22723854\n","Iteration 58, loss = 0.22688705\n","Iteration 59, loss = 0.22578745\n","Iteration 60, loss = 0.22493210\n","Iteration 61, loss = 0.22357326\n","Iteration 62, loss = 0.22214230\n","Iteration 63, loss = 0.22169288\n","Iteration 64, loss = 0.22184649\n","Iteration 65, loss = 0.21949082\n","Iteration 66, loss = 0.21911777\n","Iteration 67, loss = 0.21861027\n","Iteration 68, loss = 0.21772043\n","Iteration 69, loss = 0.21662511\n","Iteration 70, loss = 0.21613246\n","Iteration 71, loss = 0.21577079\n","Iteration 72, loss = 0.21472291\n","Iteration 73, loss = 0.21455999\n","Iteration 74, loss = 0.21360270\n","Iteration 75, loss = 0.21235549\n","Iteration 76, loss = 0.21249940\n","Iteration 77, loss = 0.21091399\n","Iteration 78, loss = 0.20972684\n","Iteration 79, loss = 0.21151183\n","Iteration 80, loss = 0.20933436\n","Iteration 81, loss = 0.20827886\n","Iteration 82, loss = 0.20884232\n","Iteration 83, loss = 0.20710373\n","Iteration 84, loss = 0.20621498\n","Iteration 85, loss = 0.20514448\n","Iteration 86, loss = 0.20550909\n","Iteration 87, loss = 0.20756217\n","Iteration 88, loss = 0.20481476\n","Iteration 89, loss = 0.20345604\n","Iteration 90, loss = 0.20388136\n","Iteration 91, loss = 0.20289676\n","Iteration 92, loss = 0.20190887\n","Iteration 93, loss = 0.20148733\n","Iteration 94, loss = 0.20204293\n","Iteration 95, loss = 0.20105382\n","Iteration 96, loss = 0.19979032\n","Iteration 97, loss = 0.19914325\n","Iteration 98, loss = 0.19895450\n","Iteration 99, loss = 0.19886374\n","Iteration 100, loss = 0.19779495\n","Iteration 101, loss = 0.19790967\n","Iteration 102, loss = 0.19716512\n","Iteration 103, loss = 0.19695985\n","Iteration 104, loss = 0.19529738\n","Iteration 105, loss = 0.19467535\n","Iteration 106, loss = 0.19588227\n","Iteration 107, loss = 0.19478244\n","Iteration 108, loss = 0.19343816\n","Iteration 109, loss = 0.19285573\n","Iteration 110, loss = 0.19338226\n","Iteration 111, loss = 0.19262169\n","Iteration 112, loss = 0.19133478\n","Iteration 113, loss = 0.19056707\n","Iteration 114, loss = 0.19144653\n","Iteration 115, loss = 0.19029264\n","Iteration 116, loss = 0.19132539\n","Iteration 117, loss = 0.19202295\n","Iteration 118, loss = 0.18943955\n","Iteration 119, loss = 0.19012437\n","Iteration 120, loss = 0.18867912\n","Iteration 121, loss = 0.18760264\n","Iteration 122, loss = 0.18783176\n","Iteration 123, loss = 0.18822457\n","Iteration 124, loss = 0.18673705\n","Iteration 125, loss = 0.18728950\n","Iteration 126, loss = 0.18646720\n","Iteration 127, loss = 0.18682620\n","Iteration 128, loss = 0.18665494\n","Iteration 129, loss = 0.18663224\n","Iteration 130, loss = 0.18517637\n","Iteration 131, loss = 0.18416600\n","Iteration 132, loss = 0.18415549\n","Iteration 133, loss = 0.18418083\n","Iteration 134, loss = 0.18339179\n","Iteration 135, loss = 0.18294093\n","Iteration 136, loss = 0.18355040\n","Iteration 137, loss = 0.18151947\n","Iteration 138, loss = 0.18348549\n","Iteration 139, loss = 0.18150072\n","Iteration 140, loss = 0.18163714\n","Iteration 141, loss = 0.18238438\n","Iteration 142, loss = 0.18057265\n","Iteration 143, loss = 0.18082456\n","Iteration 144, loss = 0.18039220\n","Iteration 145, loss = 0.18094969\n","Iteration 146, loss = 0.17963062\n","Iteration 147, loss = 0.18024972\n","Iteration 148, loss = 0.18042405\n","Iteration 149, loss = 0.17902864\n","Iteration 150, loss = 0.17985501\n","Iteration 151, loss = 0.17761839\n","Iteration 152, loss = 0.17810984\n","Iteration 153, loss = 0.17728396\n","Iteration 154, loss = 0.17749949\n","Iteration 155, loss = 0.17749298\n","Iteration 156, loss = 0.17728187\n","Iteration 157, loss = 0.17656773\n","Iteration 158, loss = 0.17615316\n","Iteration 159, loss = 0.17594215\n","Iteration 160, loss = 0.17516470\n","Iteration 161, loss = 0.17740178\n","Iteration 162, loss = 0.17523625\n","Iteration 163, loss = 0.17521089\n","Iteration 164, loss = 0.17489233\n","Iteration 165, loss = 0.17333332\n","Iteration 166, loss = 0.17531851\n","Iteration 167, loss = 0.17353838\n","Iteration 168, loss = 0.17329997\n","Iteration 169, loss = 0.17249466\n","Iteration 170, loss = 0.17291203\n","Iteration 171, loss = 0.17259546\n","Iteration 172, loss = 0.17187894\n","Iteration 173, loss = 0.17316190\n","Iteration 174, loss = 0.17365654\n","Iteration 175, loss = 0.17278221\n","Iteration 176, loss = 0.17108242\n","Iteration 177, loss = 0.17131187\n","Iteration 178, loss = 0.17177364\n","Iteration 179, loss = 0.17032761\n","Iteration 180, loss = 0.16876076\n","Iteration 181, loss = 0.16898337\n","Iteration 182, loss = 0.16954988\n","Iteration 183, loss = 0.16848470\n","Iteration 184, loss = 0.16993546\n","Iteration 185, loss = 0.17064619\n","Iteration 186, loss = 0.17090018\n","Iteration 187, loss = 0.16892124\n","Iteration 188, loss = 0.16771848\n","Iteration 189, loss = 0.16764437\n","Iteration 190, loss = 0.16660046\n","Iteration 191, loss = 0.16918923\n","Iteration 192, loss = 0.16634079\n","Iteration 193, loss = 0.16736930\n","Iteration 194, loss = 0.16881638\n","Iteration 195, loss = 0.16842297\n","Iteration 196, loss = 0.16775405\n","Iteration 197, loss = 0.16634537\n","Iteration 198, loss = 0.16696631\n","Iteration 199, loss = 0.16558776\n","Iteration 200, loss = 0.16521194\n","Iteration 201, loss = 0.16456419\n","Iteration 202, loss = 0.16556711\n","Iteration 203, loss = 0.16415876\n","Iteration 204, loss = 0.16679337\n","Iteration 205, loss = 0.16465112\n","Iteration 206, loss = 0.16471667\n","Iteration 207, loss = 0.16627452\n","Iteration 208, loss = 0.16619619\n","Iteration 209, loss = 0.16478290\n","Iteration 210, loss = 0.16307694\n","Iteration 211, loss = 0.16316302\n","Iteration 212, loss = 0.16324366\n","Iteration 213, loss = 0.16351529\n","Iteration 214, loss = 0.16508914\n","Iteration 215, loss = 0.16295744\n","Iteration 216, loss = 0.16327558\n","Iteration 217, loss = 0.16186689\n","Iteration 218, loss = 0.16177054\n","Iteration 219, loss = 0.16118771\n","Iteration 220, loss = 0.16481972\n","Iteration 221, loss = 0.16318083\n","Iteration 222, loss = 0.16318763\n","Iteration 223, loss = 0.16167173\n","Iteration 224, loss = 0.16276954\n","Iteration 225, loss = 0.16095363\n","Iteration 226, loss = 0.15919221\n","Iteration 227, loss = 0.16136531\n","Iteration 228, loss = 0.16130409\n","Iteration 229, loss = 0.16074393\n","Iteration 230, loss = 0.16066228\n","Iteration 231, loss = 0.16023604\n","Iteration 232, loss = 0.16076514\n","Iteration 233, loss = 0.16004403\n","Iteration 234, loss = 0.15964856\n","Iteration 235, loss = 0.15938137\n","Iteration 236, loss = 0.15878948\n","Iteration 237, loss = 0.16085418\n","Iteration 238, loss = 0.15838497\n","Iteration 239, loss = 0.15802517\n","Iteration 240, loss = 0.15741389\n","Iteration 241, loss = 0.15892390\n","Iteration 242, loss = 0.15911022\n","Iteration 243, loss = 0.15716498\n","Iteration 244, loss = 0.15819653\n","Iteration 245, loss = 0.15833844\n","Iteration 246, loss = 0.15671103\n","Iteration 247, loss = 0.15648988\n","Iteration 248, loss = 0.15786176\n","Iteration 249, loss = 0.15876588\n","Iteration 250, loss = 0.15816080\n","Iteration 251, loss = 0.15746897\n","Iteration 252, loss = 0.15673264\n","Iteration 253, loss = 0.15524841\n","Iteration 254, loss = 0.15588391\n","Iteration 255, loss = 0.15525138\n","Iteration 256, loss = 0.15573478\n","Iteration 257, loss = 0.15449147\n","Iteration 258, loss = 0.15578314\n","Iteration 259, loss = 0.15395017\n","Iteration 260, loss = 0.15562815\n","Iteration 261, loss = 0.15507646\n","Iteration 262, loss = 0.15481303\n","Iteration 263, loss = 0.15906241\n","Iteration 264, loss = 0.15576575\n","Iteration 265, loss = 0.15383186\n","Iteration 266, loss = 0.15430279\n","Iteration 267, loss = 0.15364539\n","Iteration 268, loss = 0.15328816\n","Iteration 269, loss = 0.15282438\n","Iteration 270, loss = 0.15235309\n","Iteration 271, loss = 0.15440478\n","Iteration 272, loss = 0.15410915\n","Iteration 273, loss = 0.15293316\n","Iteration 274, loss = 0.15271085\n","Iteration 275, loss = 0.15230030\n","Iteration 276, loss = 0.15216910\n","Iteration 277, loss = 0.15250645\n","Iteration 278, loss = 0.15141164\n","Iteration 279, loss = 0.15186471\n","Iteration 280, loss = 0.15224035\n","Iteration 281, loss = 0.15231670\n","Iteration 282, loss = 0.15305741\n","Iteration 283, loss = 0.15034852\n","Iteration 284, loss = 0.15018372\n","Iteration 285, loss = 0.15064896\n","Iteration 286, loss = 0.15201643\n","Iteration 287, loss = 0.15204273\n","Iteration 288, loss = 0.15084966\n","Iteration 289, loss = 0.15151807\n","Iteration 290, loss = 0.15008411\n","Iteration 291, loss = 0.15090586\n","Iteration 292, loss = 0.15147584\n","Iteration 293, loss = 0.15189004\n","Iteration 294, loss = 0.15316219\n","Iteration 295, loss = 0.14916655\n","Iteration 296, loss = 0.14977765\n","Iteration 297, loss = 0.14849729\n","Iteration 298, loss = 0.14955406\n","Iteration 299, loss = 0.15078620\n","Iteration 300, loss = 0.15307472\n","Iteration 301, loss = 0.15126972\n","Iteration 302, loss = 0.14843943\n","Iteration 303, loss = 0.14878442\n","Iteration 304, loss = 0.14768283\n","Iteration 305, loss = 0.14810119\n","Iteration 306, loss = 0.15173417\n","Iteration 307, loss = 0.14750139\n","Iteration 308, loss = 0.14979952\n","Iteration 309, loss = 0.14910112\n","Iteration 310, loss = 0.14818496\n","Iteration 311, loss = 0.14976061\n","Iteration 312, loss = 0.14908372\n","Iteration 313, loss = 0.14787229\n","Iteration 314, loss = 0.14859688\n","Iteration 315, loss = 0.14793495\n","Iteration 316, loss = 0.14991828\n","Iteration 317, loss = 0.14674658\n","Iteration 318, loss = 0.14918075\n","Iteration 319, loss = 0.14599777\n","Iteration 320, loss = 0.14814742\n","Iteration 321, loss = 0.14816482\n","Iteration 322, loss = 0.14745125\n","Iteration 323, loss = 0.14803325\n","Iteration 324, loss = 0.14755970\n","Iteration 325, loss = 0.14600519\n","Iteration 326, loss = 0.14568726\n","Iteration 327, loss = 0.14783792\n","Iteration 328, loss = 0.14554042\n","Iteration 329, loss = 0.14661526\n","Iteration 330, loss = 0.14459737\n","Iteration 331, loss = 0.14769261\n","Iteration 332, loss = 0.14816075\n","Iteration 333, loss = 0.14389879\n","Iteration 334, loss = 0.14578203\n","Iteration 335, loss = 0.14426392\n","Iteration 336, loss = 0.14483517\n","Iteration 337, loss = 0.14502432\n","Iteration 338, loss = 0.14638310\n","Iteration 339, loss = 0.14702900\n","Iteration 340, loss = 0.14444138\n","Iteration 341, loss = 0.14440022\n","Iteration 342, loss = 0.14644131\n","Iteration 343, loss = 0.14501462\n","Iteration 344, loss = 0.14287108\n","Iteration 345, loss = 0.14467689\n","Iteration 346, loss = 0.14406963\n","Iteration 347, loss = 0.14404143\n","Iteration 348, loss = 0.14363708\n","Iteration 349, loss = 0.14402692\n","Iteration 350, loss = 0.14401656\n","Iteration 351, loss = 0.14445775\n","Iteration 352, loss = 0.14400206\n","Iteration 353, loss = 0.14603855\n","Iteration 354, loss = 0.14445700\n","Iteration 355, loss = 0.14292913\n","Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"]},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(hidden_layer_sizes=(55, 55), max_iter=1000, tol=1e-05,\n","              verbose=True)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["previsoes = rede_neural_census.predict(x_census_teste)\n","previsoes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVLzbU7ZD203","executionInfo":{"status":"ok","timestamp":1642792866634,"user_tz":180,"elapsed":29,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"1a2632e4-c348-48a1-b3cd-01e3eb1b2f1d"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' <=50K', ' <=50K', ' <=50K', ..., ' <=50K', ' <=50K', ' >50K'],\n","      dtype='<U6')"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["y_census_teste"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKuln9KwD23J","executionInfo":{"status":"ok","timestamp":1642792866634,"user_tz":180,"elapsed":23,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"7151783e-139b-4652-be80-15bd3caf089a"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([' <=50K', ' <=50K', ' <=50K', ..., ' <=50K', ' <=50K', ' <=50K'],\n","      dtype=object)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report\n","accuracy_score(y_census_teste, previsoes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyD7_gzaD25R","executionInfo":{"status":"ok","timestamp":1642792866635,"user_tz":180,"elapsed":22,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"c6891d49-715c-402c-b851-193e1d67626a"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8171954964176049"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["from yellowbrick.classifier import ConfusionMatrix\n","cm = ConfusionMatrix(rede_neural_census)\n","cm.fit(x_census_treinamento, y_census_treinamento)\n","cm.score(x_census_teste, y_census_teste)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"uOyeEtiVD27w","executionInfo":{"status":"ok","timestamp":1642792866636,"user_tz":180,"elapsed":21,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"49711241-e123-43a6-eec2-f364e9487e53"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8171954964176049"]},"metadata":{},"execution_count":21},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["print(classification_report(y_census_teste, previsoes))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbYvPfL5D2-F","executionInfo":{"status":"ok","timestamp":1642792866636,"user_tz":180,"elapsed":19,"user":{"displayName":"Guilherme Alencar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05509345245494917113"}},"outputId":"89d5ac69-a560-40ee-9b03-862553074c28"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       <=50K       0.87      0.89      0.88      3693\n","        >50K       0.63      0.59      0.61      1192\n","\n","    accuracy                           0.82      4885\n","   macro avg       0.75      0.74      0.75      4885\n","weighted avg       0.81      0.82      0.82      4885\n","\n"]}]}]}